\documentclass{beamer}

% Top-aligning columns within a top-aligned frame
% https://tex.stackexchange.com/questions/16447/beamer-top-aligning-columns-within-a-top-aligned-frame
\makeatletter
\newenvironment{myitemize}{%
   \setlength{\topsep}{0pt}
   \setlength{\partopsep}{0pt}
   \renewcommand*{\@listi}{\leftmargin\leftmargini \parsep\z@ \topsep\z@ \itemsep\z@}
   \let\@listI\@listi
   \itemize
}{\enditemize}
\makeatother  

\usepackage[USenglish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amssymb, amsmath}
\usepackage{bm}
\usepackage{color}
\usepackage{tikz}
\usepackage{url}
\hypersetup{
    colorlinks,
    citecolor=blue,
    filecolor=blue,
    linkcolor=blue,
    urlcolor=blue
}

\usetheme{Warsaw}
\setbeamertemplate{headline}{}
\newcommand*\oldmacro{}%
\let\oldmacro\insertshorttitle%
\renewcommand*\insertshorttitle{%
  \oldmacro\hfill%
  \insertframenumber\,/\,\inserttotalframenumber}
  

\bibliographystyle{apalike}
% make bibliography entries smaller
%\renewcommand\bibfont{\scriptsize}
% Now get rid of all the colours
\setbeamercolor*{bibliography entry title}{fg=black}
\setbeamercolor*{bibliography entry author}{fg=black}
\setbeamercolor*{bibliography entry location}{fg=black}
\setbeamercolor*{bibliography entry note}{fg=black}

% and kill the abominable icon
\setbeamertemplate{bibliography item}{}

\begin{document}
\title{Objects that sound }  
\subtitle{unsupervised localization of sources of sounds in images trained from videos}
\author{Radek Bartyzal}
\date{Date TBA} 
\institute{Let's talk ML in Prague}

\frame{\titlepage} 

\begin{frame}{Achievements}

Achievements:

\begin{itemize}

\item networks that can embed audio and visual inputs into a common space that is suitable for cross-modal retrieval
\medskip
\item network that can localize the object that sounds in an image, given the audio signal
\medskip
\item training from unlabelled video using only audio-visual correspondence (AVC) as the objective function. 
\end{itemize}
\medskip

\begin{block}{Cross-modal retrieval}
Use audio to search in an image.
\end{block}

\begin{block}{Self-supervision}
Labels are constructed directly from data.
\end{block}

\end{frame}
%--------- END Frame 1 -------------

\begin{frame}{Audio-visual correspondence (AVC)}

\begin{itemize}
\item[Input:] Pair of a video frame and 1 second of audio.
\medskip
\item[Task:] Are they in correspondence or not?
\medskip
\item[Labels:] Obtained directly from video for both positives
(matching) and negatives (mismatched) pairs. 
\end{itemize}

\vfill

Learnt visual and audio representations are:
\begin{itemize}
\item discriminative = distinguish matched and mismatched pairs
\item semantically meaningful = network has to find semantical match between audio and an image (visual network has only 1 image as input)
\end{itemize}

\end{frame}
%--------- END Frame 2 -------------

\begin{frame}{Previous work - $L^3$}

%$L^3$ = Look, Listen & Learn \cite{cit:l3}




\end{frame}
%--------- END Frame 3 -------------

\begin{frame}{Previous work - $L^3$}


\end{frame}
%--------- END Frame 4 -------------
\begin{frame}{Audio-Visual Embedding Network (AVENet)}


\end{frame}
%--------- END Frame 5 -------------
\begin{frame}{Audio-Visual Embedding Network (AVENet)}

 

\end{frame}
%--------- END Frame 6 -------------
\begin{frame}{Extending the AVE-Net}


\end{frame}
%--------- END Frame 7 -------------
\begin{frame}{Audio-Visual Object Localization (AVOL-Net)}


\end{frame}
%--------- END Frame 8 -------------
\begin{frame}{: Audio-Visual Object Localization (AVOL-Net)}



\end{frame}
%--------- END Frame 9 -------------
\begin{frame}{ResNets reminder}

\end{frame}
%--------- END Frame 10 -------------
\begin{frame}{BAN ResNets}

\end{frame}
%--------- END Frame 11 -------------
\begin{frame}{BAN Results}


\end{frame}

%--------- END Frame 12 -------------
\begin{frame}{Sources}

\begin{thebibliography}{0}

  \bibitem[1]{cit:ots} ArandjeloviÄ‡, Relja, and Andrew Zisserman. "Objects that Sound." arXiv preprint arXiv:1712.06651 (2017). Accessible from: \url{https://arxiv.org/abs/1712.06651}
  
  \bibitem[2]{cit:l3} Arandjelovic, Relja, and Andrew Zisserman. "Look, listen and learn." 2017 IEEE International Conference on Computer Vision (ICCV). IEEE, 2017. Accessible from: \url{https://arxiv.org/abs/1705.08168}
\end{thebibliography}
\end{frame}
 
 
 
\end{document}
